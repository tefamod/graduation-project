{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Load your dataset\n",
        "# Assuming your data is in a CSV file named 'your_data.csv'\n",
        "data = pd.read_csv('Robot_train_4s.csv')\n",
        "\n",
        "# 1. Data Preprocessing\n",
        "# Example: Handle missing values\n",
        "data = data.dropna()\n",
        "\n",
        "# Example: Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data.drop('Label', axis=1))  # Assuming 'label' is the column name for your output\n",
        "\n",
        "# 2. Splitting the Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_scaled, data['Label'], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIqIL-QI39q9",
        "outputId": "76c5fc8e-39c9-404a-c892-c3312ff4a108"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Accuracy: 0.9986064659977704\n",
            "Final Random Forest Accuracy: 0.9977703455964325\n",
            "Cross-Validation Scores: [0.99825784 0.99686411 0.9989547  0.99860579 0.99895434]\n",
            "Mean Cross-Validation Score: 0.9983273561063051\n",
            "Feature Importance: [0.24537885 0.21225576 0.21899106 0.2018219  0.12155244]\n"
          ]
        }
      ],
      "source": [
        "# 3. Building Multiple ML Models\n",
        "# Example: Random Forest\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Model Evaluation\n",
        "y_pred = rf_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Random Forest Accuracy: {accuracy}')\n",
        "\n",
        "# 5. Feature Selection using RFE\n",
        "# Assuming you want to keep 5 features\n",
        "num_features_to_keep = 5\n",
        "rfe = RFE(estimator=rf_model, n_features_to_select=num_features_to_keep)\n",
        "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
        "X_test_rfe = rfe.transform(X_test)\n",
        "\n",
        "# 6. Fine-tuning (Optional)\n",
        "# Example: Hyperparameter tuning for Random Forest\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
        "                           param_grid=param_grid,\n",
        "                           scoring='accuracy',\n",
        "                           cv=cv,\n",
        "                           n_jobs=-1)\n",
        "grid_search.fit(X_train_rfe, y_train)\n",
        "\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "# 7. Final Model\n",
        "best_rf_model.fit(X_train_rfe, y_train)\n",
        "\n",
        "# 8. Model Evaluation\n",
        "y_pred_final = best_rf_model.predict(X_test_rfe)\n",
        "accuracy_final = accuracy_score(y_test, y_pred_final)\n",
        "print(f'Final Random Forest Accuracy: {accuracy_final}')\n",
        "\n",
        "# Additional Steps: Cross-Validation, Ensemble Methods, Feature Importance\n",
        "# Example: Cross-Validation\n",
        "cv_scores = cross_val_score(best_rf_model, X_train_rfe, y_train, cv=cv, scoring='accuracy')\n",
        "print(f'Cross-Validation Scores: {cv_scores}')\n",
        "print(f'Mean Cross-Validation Score: {cv_scores.mean()}')\n",
        "\n",
        "# Example: Feature Importance\n",
        "feature_importance = best_rf_model.feature_importances_\n",
        "print(f'Feature Importance: {feature_importance}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp4Hsy1___ym",
        "outputId": "81081f14-2a35-47ef-a0a2-a0817f3eec1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Accuracy: 0.9531772575250836\n",
            "Final SVM Accuracy: 0.9278149386845039\n",
            "Cross-Validation Scores: [0.92849676 0.92556973 0.9259724 ]\n",
            "Mean Cross-Validation Score: 0.9266796273187321\n"
          ]
        }
      ],
      "source": [
        "# 3. Building Multiple ML Models\n",
        "# Example: Support Vector Machine (SVM)\n",
        "svm_model = SVC(kernel='linear', random_state=42)  # You can choose different kernels (linear, rbf, etc.)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Model Evaluation\n",
        "y_pred = svm_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'SVM Accuracy: {accuracy}')\n",
        "\n",
        "# 5. Feature Selection using RFE\n",
        "# Assuming you want to keep 3 features\n",
        "num_features_to_keep = 3\n",
        "rfe = RFE(estimator=svm_model, n_features_to_select=num_features_to_keep)\n",
        "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
        "X_test_rfe = rfe.transform(X_test)\n",
        "\n",
        "# 6. Fine-tuning (Optional)\n",
        "# Example: Hyperparameter tuning for SVM\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'gamma': [0.001, 0.01, 0.1],\n",
        "    'kernel': ['linear', 'rbf', 'poly']\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "grid_search = GridSearchCV(estimator=SVC(random_state=42),\n",
        "                           param_grid=param_grid,\n",
        "                           scoring='accuracy',\n",
        "                           cv=cv,\n",
        "                           n_jobs=-1)\n",
        "grid_search.fit(X_train_rfe, y_train)\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "\n",
        "# 7. Final Model\n",
        "best_svm_model.fit(X_train_rfe, y_train)\n",
        "\n",
        "# 8. Model Evaluation\n",
        "y_pred_final = best_svm_model.predict(X_test_rfe)\n",
        "accuracy_final = accuracy_score(y_test, y_pred_final)\n",
        "print(f'Final SVM Accuracy: {accuracy_final}')\n",
        "\n",
        "# Additional Steps: Cross-Validation, Ensemble Methods, Feature Importance\n",
        "# Example: Cross-Validation\n",
        "cv_scores = cross_val_score(best_svm_model, X_train_rfe, y_train, cv=cv, scoring='accuracy')\n",
        "print(f'Cross-Validation Scores: {cv_scores}')\n",
        "print(f'Mean Cross-Validation Score: {cv_scores.mean()}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSeFekctDd-U",
        "outputId": "f3b21ecc-d931-4982-f357-bf99cb600603"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient Boosting Accuracy: 0.9980490523968785\n"
          ]
        }
      ],
      "source": [
        "# 3. Building Multiple ML Models\n",
        "# Example: Gradient Boosting\n",
        "gb_model = GradientBoostingClassifier(random_state=42)\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Model Evaluation\n",
        "y_pred = gb_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Gradient Boosting Accuracy: {accuracy}')\n",
        "\n",
        "# 5. Feature Selection using RFE\n",
        "# Assuming you want to keep 3 features\n",
        "num_features_to_keep = 3\n",
        "rfe = RFE(estimator=gb_model, n_features_to_select=num_features_to_keep)\n",
        "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
        "X_test_rfe = rfe.transform(X_test)\n",
        "\n",
        "# 6. Fine-tuning (Optional)\n",
        "# Example: Hyperparameter tuning for Gradient Boosting\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 4, 5]\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "grid_search = GridSearchCV(estimator=GradientBoostingClassifier(random_state=42),\n",
        "                           param_grid=param_grid,\n",
        "                           scoring='accuracy',\n",
        "                           cv=cv,\n",
        "                           n_jobs=-1)\n",
        "grid_search.fit(X_train_rfe, y_train)\n",
        "\n",
        "best_gb_model = grid_search.best_estimator_\n",
        "\n",
        "# 7. Final Model\n",
        "best_gb_model.fit(X_train_rfe, y_train)\n",
        "\n",
        "# 8. Model Evaluation\n",
        "y_pred_final = best_gb_model.predict(X_test_rfe)\n",
        "accuracy_final = accuracy_score(y_test, y_pred_final)\n",
        "print(f'Final Gradient Boosting Accuracy: {accuracy_final}')\n",
        "\n",
        "# Additional Steps: Cross-Validation, Ensemble Methods, Feature Importance\n",
        "# Example: Cross-Validation\n",
        "cv_scores = cross_val_score(best_gb_model, X_train_rfe, y_train, cv=cv, scoring='accuracy')\n",
        "print(f'Cross-Validation Scores: {cv_scores}')\n",
        "print(f'Mean Cross-Validation Score: {cv_scores.mean()}')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
